{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Federated Learning for Healthcare","text":"<p>Welcome to the Federated Learning tutorial that will be run in conjunction with multiple conferences!</p> <p>Federated Learning (FL) is increasingly important in privacy sensitive domains, such as healthcare, where sharing of private/patient data is a barrier to building models that generalize well in the real world and minimize bias.</p> <p>In this tutorial, we will be presenting the COmprehensive Federated Ecosystem (COFE), which comprises of the following components:</p> <ol> <li>The Generally Nuanced Deep Learning Framework (GaNDLF) - gandlf.org</li> <li>MedPerf - www.medperf.org</li> <li>OpenFL - github.com/securefederatedai/openfl</li> </ol> <p>In 2021, COFE was used to conduct the largest to-date real world federation, with a network of 71 healthcare institutions around the world, the Federated Tumor Segmentation (FeTS) Initiative [ref]. Furthermore, leveraging the collaborators of this real-world FL initiative, the first ever FL challenge was conducted, which focused on the tumor segmentation task, called The FeTS 2021 challenge [ref], which was conducted again in 2022 [ref]. Taking into consideration the value and the interest of the community in this new paradigm for data private multi-institutional collaborations and building upon our experience, we organize this tutorial on FL for healthcare.</p>"},{"location":"#upcoming-events","title":"Upcoming Events","text":"<ul> <li>Bridge Event at AAAI 2024</li> </ul>"},{"location":"#past-events","title":"Past Events","text":"<ul> <li>Tutorial in MICCAI 2023</li> <li>Tutorial in MICCAI 2022</li> </ul>"},{"location":"#organizing-committee","title":"Organizing Committee","text":"<ul> <li>Sarthak Pati, Indiana University &amp; MLCommons.</li> <li>Patrick Foley, Intel Corporation.</li> <li>Hasan Kassem, MLCommons.</li> <li>Alex Karargyris, MLCommons.</li> <li>Spyridon Bakas, Indiana University &amp; MLCommons.</li> </ul>"},{"location":"#tutorial-description","title":"Tutorial Description","text":"<p>The aim of this tutorial is to facilitate education on how to perform Federated Learning on both simulated and real-world studies. Tutorial structure focuses on specific clearly indicated parts for beginners and for more advanced attendees. Data scientists of different medical imaging communities (e.g., radiology, pathology) are considered during this tutorial on the opportunities and challenges in developing and using FL for training Al models across institutions using privacy preserving techniques. We plan on covering a spectrum of techniques, from software-based approaches that can be considered a method or a metric (e.g., differential privacy), to hardware-based trusted execution computing environments (TEEs).</p> <p>The motivation for the tutorial is driven by the need to train and validate deep learning models across data silos, to create models that gain knowledge from diverse patient populations and hence generalize well, mitigate bias, and pave the way towards addressing health disparities.</p>"},{"location":"index_2022/","title":":warning: Copied from previous FL-Tutorial page :warning:","text":""},{"location":"index_2022/#federated-learning-for-healthcare","title":"Federated Learning for Healthcare","text":"<p>Welcome to the Federated Learning tutorial that will be run in conjunction with the MICCAI conference!</p> <p>Federated Learning (FL) is increasingly important in privacy sensitive domains, such as healthcare, where sharing of private/patient data is a barrier to building models that generalize well in the real world and minimize bias.  </p> <p>In 2021, we led the largest real world federation, with a network of 59 healthcare institutions around the world. Furthermore, leveraging the collaborators of this real-world FL initiative, we led the first ever FL challenge, focusing on the tumor segmentation task, called The FeTS 2021 challenge. Taking into consideration the value and the interest of the community in this new paradigm for data private multi-institutional collaborations and building upon our experience, we organize this tutorial on FL for healthcare.</p> <p>The tutorial will teach you how to use state-of-the-art open-source Python library for Federated Learning OpenFL.</p>"},{"location":"index_2022/#when-and-where","title":"When and Where?","text":"<p>September 22nd from 11:50 to 15:20 (SGT time)</p> <p>Sign up as a virtual tutorial attendee until the day of the event at the MICCAI Registration Page</p>"},{"location":"index_2022/#organizing-committee","title":"Organizing Committee","text":"<ul> <li>Ujjwal Baid, University of Pennsylvania.</li> <li>Spyridon Bakas, University of Pennsylvania.</li> <li>Patrick Foley, Intel Corporation.</li> <li>Sarthak Pati, University of Pennsylvania.</li> <li>Prashant Shah, Intel Corporation.</li> <li>Mansi Sharma, Intel Corporation.</li> <li>Micah Sheller, Intel Corporation.</li> <li>Karan Shah, Intel Corporation.</li> </ul>"},{"location":"index_2022/#tutorial-description","title":"Tutorial Description","text":"<p>The aim of this tutorial is to facilitate education on how to perform Federated Learning on both simulated and real-world studies. Tutorial structure focuses on specific clearly indicated parts for beginners and for more advanced attendees. Data scientists of different medical imaging communities (e.g., radiology, pathology) are considered during this tutorial on the opportunities and challenges in developing and using FL for training Al models across institutions using privacy preserving techniques. We plan on covering a spectrum of techniques, from software-based approaches that can be considered a method or a metric (e.g., differential privacy), to hardware-based trusted execution computing environments (TEEs).</p> <p>The motivation for the tutorial is driven by the need to train and validate deep learning models across data silos, to create models that gain knowledge from diverse patient populations and hence generalize well, mitigate bias, and pave the way towards addressing health disparities.</p>"},{"location":"index_2022/#preliminary-program","title":"Preliminary program","text":""},{"location":"index_2022/#part-i-45-minutes-environment-setup","title":"Part I (45 minutes, environment setup)","text":"<ul> <li>Get access to the Google Colab enviroment</li> </ul>"},{"location":"index_2022/#part-ii-45-minutes-lecture-based","title":"Part II (45 minutes, lecture based)","text":"<ul> <li>Introduction to FL</li> <li>Considerations for FL, based on what we learned from: </li> <li>The largest known real-world global federation FeTS, and</li> <li>The first ever proposal challenge on federated learning MICCAI 2021 FeTS challenge.</li> </ul>"},{"location":"index_2022/#part-iii-2h-hands-on","title":"Part III (~2h, Hands on)","text":"<ul> <li>Hands-on and interactive tutorial on simulating federations and training various segmentation and classification models, while taking into account numerous considerations (including but not limited to a) data size across collaborators, b) network delays in sharing model weights).</li> </ul> <p>Data Scientists and Computational Scientists attending this tutorial will be able to adapt their existing centralized algorithms to a federated architecture or build new models. Non-data scientists (e.g., more clinically-oriented attendees of the CLINICAI sessions) will learn about both technical and non-technical considerations setting up federations for training medical Al models. Importantly, attendees will also understand the privacy and security attack vectors and mitigations when using FL.</p>"},{"location":"index_2022/#speakers","title":"Speakers","text":"<ul> <li> <p>Spyridon Bakas, Ph.D., is an Assistant Professor at the University of Pennsylvania, focusing on computational algorithms for oncological imaging, towards improving the clinical practice.</p> </li> <li> <p>Patrick Foley is a Senior Deep Learning (DL) Software Engineer at Intel and Lead Architect of OpenFL, an open-source library for FL.</p> </li> <li> <p>Mansi Sharma is a Deep Learning (DL) Software Engineer at Intel  and a developer of OpenFL, an open-source library for FL.</p> </li> <li> <p>Karan Shah is an Applied Machine Learning Engineer at Intel and a developer of OpenFL. His interests span Deep Learning, Optimization Theory, Statistics and Cosmology.</p> </li> <li> <p>Sarthak Pati, M.Sc., is a Sr. Application Developer at UPenn. He focuses on ML, distributed, and privacy-protected algorithms for healthcare, and currently leads the R&amp;D of the FeTS platform.</p> </li> </ul>"},{"location":"index_2022/#format","title":"Format","text":"<p>Half day (afternoon), Hands-on</p>"},{"location":"index_2022/#proceedings","title":"Proceedings","text":"<p>In favor of open science, transparency, and further communicating the information presented during the tutorial beyond its actual lifecycle during MICCAI 2021, we intend to produce tutorial notes and be part of the MICCAI satellite event proceedings.</p>"},{"location":"tutorial/","title":"Tutorial","text":""},{"location":"tutorial/#setup","title":"Setup","text":"<p>For the tutorial, we will be using a local MedPerf server and a local mocked auth provider. The MedPerf client installed in your virtual machines is preconfigured to communicate with the local server.</p> <p>Now to run the local server,</p> <p>Run:</p> <pre><code>conda activate medperf\ncd ~/medperf/server\nsh setup-dev-server.sh\n</code></pre>"},{"location":"tutorial/#medperf-client-installation-and-authentication","title":"MedPerf Client Installation and Authentication","text":"<p>All involved parties that intend to use the MedPerf client will have to signup for a MedPerf account, install the client, and login prior to using it.</p> <p>For our tutorial, we already setup the virtual machines with MedPerf preinstalled. We will use the <code>Local</code> profile config.</p> <pre><code>conda activate medperf\nmedperf --version\n</code></pre> <p>Check profiles by running <code>medperf profile view</code>. You will see <code>server: https://localhost:8000</code> and the auth configuration used is <code>Local</code>.</p>"},{"location":"tutorial/#training-setup-with-medperf-model-owner","title":"Training Setup with MedPerf (Model Owner)","text":"<pre><code>medperf auth login -e modelowner@example.com\n</code></pre>"},{"location":"tutorial/#define-the-data-preparation-mlcube","title":"Define the data preparation MLCube","text":"<ul> <li>Prepare the data preparation pipeline logic that will transform the raw clinical data into AI-ready data. This will be an MLCube</li> </ul>"},{"location":"tutorial/#register-the-mlcube","title":"Register the MLCube","text":"<pre><code>medperf mlcube submit -n prep \\\n-m https://storage.googleapis.com/medperf-storage/testfl/mlcube_prep.yaml\n</code></pre>"},{"location":"tutorial/#define-the-training-mlcube","title":"Define the training MLCube","text":"<ul> <li>Prepare the training logic using OpenFL and GaNDLF</li> </ul>"},{"location":"tutorial/#register-the-training-mlcube","title":"Register the Training MLCube","text":"<pre><code>medperf mlcube submit -n traincube \\\n-m https://storage.googleapis.com/medperf-storage/testfl/mlcube-cpu.yaml?v=2 \\\n-p https://storage.googleapis.com/medperf-storage/testfl/parameters-miccai.yaml \\\n-a https://storage.googleapis.com/medperf-storage/testfl/init_weights_miccai.tar.gz\n</code></pre>"},{"location":"tutorial/#register-the-training-experiment","title":"Register the Training Experiment","text":"<pre><code>medperf training submit -n trainexp -d trainexp -p 1 -m 2\n</code></pre> <p>The server admin should approve the experiment. Run:</p> <pre><code>bash admin_training_approval.sh\n</code></pre>"},{"location":"tutorial/#aggregator-setup-with-medperf-aggregator-owner","title":"Aggregator Setup with MedPerf (Aggregator Owner)","text":"<pre><code>medperf auth login -e aggowner@example.com\n</code></pre>"},{"location":"tutorial/#register-aggregator","title":"register aggregator","text":"<pre><code>medperf aggregator submit -n aggreg -a $(hostname --fqdn) -p 50273\n</code></pre>"},{"location":"tutorial/#associate-the-aggregator-with-the-experiment","title":"Associate the aggregator with the experiment","text":"<pre><code>medperf aggregator associate -a 1 -t 1\n</code></pre>"},{"location":"tutorial/#data-preparation-training-data-owner","title":"Data preparation (Training Data Owner)","text":"<pre><code>medperf auth login -e traincol1@example.com\n</code></pre>"},{"location":"tutorial/#process-your-data-using-the-data-prep-mlcube","title":"Process your data using the data prep mlcube","text":"<pre><code>medperf dataset create -p 1 -d datasets/col1 -l datasets/col1 --name col1 --description col1data --location col1location\n</code></pre>"},{"location":"tutorial/#register-your-dataset","title":"Register your dataset","text":"<p>find Hash:</p> <pre><code>medperf dataset ls\n</code></pre> <pre><code>medperf dataset submit -d &lt;hash_found&gt;\n</code></pre>"},{"location":"tutorial/#request-participation-in-the-training-experiment","title":"Request participation in the training experiment","text":"<pre><code>medperf training associate_dataset -t 1 -d 1\n</code></pre>"},{"location":"tutorial/#redo-the-same-with-collaborator-2","title":"Redo the same with collaborator 2","text":"<pre><code>bash shortcut.sh\n</code></pre>"},{"location":"tutorial/#accepting-training-participation-model-owner","title":"Accepting Training Participation (Model Owner)","text":"<pre><code>medperf auth login -e modelowner@example.com\n</code></pre>"},{"location":"tutorial/#accept-participation-requests","title":"Accept participation requests","text":"<pre><code>medperf training approve_association -t 1 -a 1\nmedperf training approve_association -t 1 -d 1\nmedperf training approve_association -t 1 -d 2\n</code></pre>"},{"location":"tutorial/#lock-the-experiment","title":"Lock the experiment","text":"<pre><code>medperf training lock -t 1\n</code></pre>"},{"location":"tutorial/#run-the-aggregator-aggregator-owner","title":"Run the Aggregator (Aggregator Owner)","text":"<pre><code>medperf auth login -e aggowner@example.com\n</code></pre> <pre><code>medperf aggregator start -a 1 -t 1\n</code></pre> <p>(Now move to another terminal)</p>"},{"location":"tutorial/#run-training-training-data-owner","title":"Run Training (Training Data Owner)","text":"<p>First collaborator:</p> <pre><code>medperf auth login -e traincol1@example.com\n</code></pre> <pre><code>medperf training run -d 1 -t 1\n</code></pre> <p>(Now move to another terminal)</p> <p>Second collaborator:</p> <pre><code>medperf auth login -e traincol2@example.com\n</code></pre> <pre><code>medperf training run -d 2 -t 1\n</code></pre>"},{"location":"tutorial/#inference-setup-with-medperf-benchmark-owner","title":"Inference Setup with MedPerf (Benchmark Owner)","text":"<pre><code>medperf auth login -e benchmarkowner@example.com\n</code></pre>"},{"location":"tutorial/#register-a-reference-model","title":"Register a reference model","text":"<pre><code>medperf mlcube submit -n refmodel \\\n-m https://storage.googleapis.com/medperf-storage/testfl/mlcube_other.yaml\n</code></pre>"},{"location":"tutorial/#register-the-metrics-mlcube","title":"Register the metrics MLCube","text":"<ul> <li>Prepare the metrics calculation logic that will be used for the evaluation and the benchmarking of multiple trained models on unseen data.</li> </ul> <pre><code>medperf mlcube submit -n metrics \\\n-m https://storage.googleapis.com/medperf-storage/testfl/mlcube_metrics.yaml \\\n-p https://storage.googleapis.com/medperf-storage/testfl/parameters_metrics.yaml\n</code></pre>"},{"location":"tutorial/#register-the-benchmark","title":"Register the benchmark","text":"<pre><code>medperf benchmark submit --name pathmnistbmk --description pathmnistbmk \\\n--demo-url https://storage.googleapis.com/medperf-storage/testfl/data/sample.tar.gz \\\n-p 1 -m 3 -e 4\n</code></pre> <p>The server admin should approve the benchmark. Run:</p> <pre><code>bash admin_benchmark_approval.sh\n</code></pre>"},{"location":"tutorial/#participate-as-a-model-owner-model-owner","title":"Participate as a model owner (Model Owner)","text":"<pre><code>medperf auth login -e modelowner@example.com\n</code></pre>"},{"location":"tutorial/#register-your-model","title":"Register your model","text":"<ul> <li>Export the trained model to an MLCube using GaNDLF</li> </ul> <pre><code>medperf mlcube submit -n trained \\\n-m https://storage.googleapis.com/medperf-storage/testfl/mlcube_trained.yaml\n</code></pre>"},{"location":"tutorial/#request-participation-in-the-benchmark","title":"Request participation in the benchmark","text":"<pre><code>medperf mlcube associate -b 1 -m 5 -y\n</code></pre>"},{"location":"tutorial/#participate-as-a-data-owner-inference-data-owner","title":"Participate as a data owner (Inference data Owner)","text":"<pre><code>medperf auth login -e testcol@example.com\n</code></pre>"},{"location":"tutorial/#process-data-using-the-data-prep-mlcube","title":"Process data using the data prep mlcube","text":"<pre><code>medperf dataset create -p 1 -d datasets/test -l datasets/test --name testdata --description testdata --location testdata\n</code></pre>"},{"location":"tutorial/#register-the-dataset","title":"Register the dataset","text":"<p>find Hash:</p> <pre><code>medperf dataset ls\n</code></pre> <pre><code>medperf dataset submit -d &lt;hash_found&gt;\n</code></pre>"},{"location":"tutorial/#request-participation","title":"Request participation","text":"<pre><code>medperf dataset associate -b 1 -d 3 -y\n</code></pre>"},{"location":"tutorial/#accepting-inference-participation-benchmark-owner","title":"Accepting Inference Participation (Benchmark Owner)","text":"<pre><code>medperf auth login -e benchmarkowner@example.com\n</code></pre> <p>Accept inference participation requests (from the model owners and data owners)</p> <pre><code>medperf association approve -b 1 -m 5\nmedperf association approve -b 1 -d 3\n</code></pre>"},{"location":"tutorial/#run-inference-inference-data-owner","title":"Run Inference (Inference Data Owner)","text":"<pre><code>medperf auth login -e testcol@example.com\n</code></pre>"},{"location":"tutorial/#start-benchmark-execution","title":"Start benchmark execution","text":"<ul> <li>models associated with the benchmark, including the reference model, will be executed on the data</li> </ul> <pre><code>medperf benchmark run -b 1 -d 3\n</code></pre>"},{"location":"tutorial/#submit-inference-results","title":"Submit inference results","text":"<pre><code>medperf result submit -r b1m5d3 -y\nmedperf result submit -r b1m3d3 -y\n</code></pre>"},{"location":"tutorial/#result-collection-benchmark-owner","title":"Result collection (Benchmark Owner)","text":"<pre><code>medperf auth login -e benchmarkowner@example.com\n</code></pre> <p>Pull and view inference results from the medperf server</p> <pre><code>medperf result view -b 1\n</code></pre>"}]}